{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxDxI1u7IoouH7qkt79g1z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenzoZanca/Numeric_Proyects/blob/main/optimizacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea numérica optimización\n",
        "\n",
        "Renzo Zanca Ruedlinger"
      ],
      "metadata": {
        "id": "NKuDxvlPV5Oh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las librerias necesarias:"
      ],
      "metadata": {
        "id": "Nnwgg8Xju8YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.optimize\n",
        "import time"
      ],
      "metadata": {
        "id": "5HZGFLJctF75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## P1\n"
      ],
      "metadata": {
        "id": "yIgQOpxRXELw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creamos la matriz de categorias considerando los siguientes correos:**\n",
        "\n",
        "\n",
        "**Correo 1:** Correo de promoción de Uber, largo mediano, en español:\n",
        "\n",
        "$x_1^1 = 1, x_1^2 = 2, x_1^3 = 2, y_1 = 1$\n",
        "\n",
        "**Correo 2:** Correo institucional de la universidad, en español, largo:\n",
        "\n",
        "$x_2^1 = 1, x_2^2 = 2, x_2^3 = 3, y_2 = 0$\n",
        "\n",
        "**Correo 3:** Correo de un amigo, en español, largo mediano:\n",
        "\n",
        "$x_3^1 = 1, x_3^2 = 1, x_3^3 = 2, y_3 = 0$\n",
        "\n",
        "**Correo 4:** Correo de un desconocido, en ingles, largo:\n",
        "\n",
        "$x_4^1 = 2, x_4^2 = 1, x_4^3 = 3, y_4 = 1$\n",
        "\n",
        "**Correo 5:** Correo de admisión universidad Santo Tomás, largo, en español:\n",
        "\n",
        "$x_5^1 = 1, x_5^2 = 2, x_5^3 = 3, y_5 = 1$\n",
        "\n",
        "**Correo 6:** correo de servidor extraño, en español, extenso, de mafioso italiano:\n",
        "\n",
        "$x_6^1 = 1, x_6^2 = 3, x_6^3 = 3, y_6 = 1$\n",
        "\n",
        "**Correo 7:** Correo de servidor extraño, promocionando cremas para pies, largo mediano, en español:\n",
        "\n",
        "$x_7^1 = 1, x_7^2 = 3, x_7^3 = 2, y_7 = 1$\n",
        "\n",
        "**Correo 8:** Correo univesitario corto, en español:\n",
        "\n",
        "$x_8^1 = 1, x_8^2 = 2, x_8^3 = 1, y_8 = 0$\n",
        "\n",
        "**Correo 9:** Correo de servidor extraño ofreciendo bitcoins gratis, en ingles, largo mediano:\n",
        "\n",
        "$x_9^1 = 2, x_9^2 = 3, x_9^3 = 2, y_9 = 1$\n",
        "\n",
        "**Correo 10:** Correo corto del banco, en español:\n",
        "\n",
        "$x_{10}^1 = 1, x_{10}^2 = 2, x_{10}^3 = 1, y_{10} = 0$\n",
        "\n",
        "**Correo 11:** Correo de compañero de universidad, corto, en español:\n",
        "\n",
        "$x_{11}^1 = 1, x_{11}^2 = 1, x_{11}^3 = 1, y_{11} = 0$\n",
        "\n",
        "**Correo 12:** Correo de empresa francesa, largo mediano, en frances:\n",
        "\n",
        "$x_{12}^1 = 3, x_{12}^2 = 2, x_{12}^3 = 2, y_{12} = 1$"
      ],
      "metadata": {
        "id": "TAVpPMJbXHLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El criterio para determinar si un correo es spam o no es simplemente mi criterio personal, pues yo soy el usuario del correo."
      ],
      "metadata": {
        "id": "LdkW0XSBtE2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo pasamos a código creando matrices y vectores con numpy:"
      ],
      "metadata": {
        "id": "-sOcAHtvvJ0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdjV_HKBVzHL"
      },
      "outputs": [],
      "source": [
        "#creamos la matriz de categorias:\n",
        "x = np.zeros(shape=(3,12), dtype='int')\n",
        "#rellenamos con los datos:\n",
        "x[0] = [1,1,1,2,1,1,1,1,2,1,1,3] #x^1\n",
        "x[1] = [2,2,1,1,2,3,3,2,3,2,1,2] #x^2\n",
        "x[2] = [2,3,2,3,3,3,2,1,2,1,1,2] #x^3\n",
        "\n",
        "#creamos el vector de respuestas:\n",
        "y = np.array([1,0,0,1,1,1,1,0,1,0,0,1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRvJ0T8AtTEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## P2"
      ],
      "metadata": {
        "id": "ux5eZ9aHoSOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables globales:\n",
        "n = 12\n",
        "k = 3"
      ],
      "metadata": {
        "id": "_71LjRI12KwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Función de pérdida de entropía cruzada:"
      ],
      "metadata": {
        "id": "yM0ecTIUoXJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para implementar esta función, se asume que la dimension de b sera igual a la de $x_i^T$, pues en la práctica siempre se cumplirá cuando se utilice. Con esto la función recibe un vector b y devuelve un arreglo con un único elemento r(b). En el código se utiliza la función np.dot(), la cual sirve para hacer productos puntos, sin importar si el vector está traspuesto o no (obtiene el mismo resultado). El algoritmo consiste en inicializar con un arreglo con un cero y luego ir sumando iterativamente cada elemento de la sumatoria."
      ],
      "metadata": {
        "id": "R-zxGzBUyKp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r(b):\n",
        "  suma = np.zeros(1, dtype='float')\n",
        "  for j in range(n):\n",
        "    suma += ((1-y[j])*np.dot(x[:,j],b) + np.log(1 + np.exp(-np.dot(x[:,j],b))))\n",
        "\n",
        "  return suma/n"
      ],
      "metadata": {
        "id": "vrgPxUmszKiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradiente de la función de pérdida de entropía cruzada"
      ],
      "metadata": {
        "id": "61fvHC4rvTad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función recibe un vector b y devuelve un arreglo con el gradiente de la función r. Como función auxiliar, se define la funcion h, la cual aparece en la expresión del gradiente; se asumira que recibe un valor escalar, pues en la práctica siempre será asi. De forma similar, el algoritmo consiste en inicializar con un arreglo con ceros y luego ir sumando iterativamente cada elemento de la sumatoria."
      ],
      "metadata": {
        "id": "rXtqS-MN0mTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def h(z):\n",
        "  return 1/(1 + np.exp(-z))\n",
        "\n",
        "def gradf(b):\n",
        "  suma = np.zeros(k, dtype='float')\n",
        "  for j in range(n):\n",
        "    suma += (np.dot((h(np.dot(x[:,j],b)) - y[j]), x[:,j]))\n",
        "\n",
        "  return suma/n"
      ],
      "metadata": {
        "id": "ZVpGpBCwz-1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matriz hessiana de la función de pérdida de entropía cruzada\n"
      ],
      "metadata": {
        "id": "t-Us0slNyju9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función recibe un vector b y devuelve un arreglo con la matriz hessiana de la función r. Se utilizara la función np.multiply() para la multiplicación de matrices. Para obtener el vector $x_i^T$ se pasa el vector x a una matriz (encerrandolo con corchetes) y luego se llama al metodo .T que transpone la matriz. De igual manera, el algoritmo consiste en inicializar con un arreglo con ceros y luego ir sumando iterativamente cada elemento de la sumatoria."
      ],
      "metadata": {
        "id": "TpwuBo-t1rYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hessf(b):\n",
        "  suma = np.zeros(shape=(3,3), dtype='float')\n",
        "  for j in range(n):\n",
        "    suma += (h(np.dot(x[:,j],b)) * ((1-h(np.dot(x[:,j],b))) * np.multiply(x[:,j], np.array([x[:,j]]).T)))\n",
        "\n",
        "  return suma/n"
      ],
      "metadata": {
        "id": "gyU0-sPG2i_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Función busqueda exacta\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AX3aojan65kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función recibe un punto b0 y una dirreción d, devolviendo el paso de una busqueda lineal exacta. Para buscar el paso a, debemos minimizar phi = r(b0 + ad), para ello usamos la función minimize_scalar de la libreria scipy.optimize."
      ],
      "metadata": {
        "id": "ZhkRJAWC2hvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def busquedaexacta(b0,d):\n",
        "  #definimos phi:\n",
        "  def phi(a):\n",
        "    return r(b0 + a*d)\n",
        "  a = scipy.optimize.minimize_scalar(phi)\n",
        "  return a.x[0]"
      ],
      "metadata": {
        "id": "eAEFkjYe7LUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Función backtracking"
      ],
      "metadata": {
        "id": "Q7AM8rwJ94ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función recibe un punto b0 y una dirreción d, devolviendo el paso al utilizar backtracking. Para buscar el paso a, usamos el algoritmo visto en clases auxiliares (resumen auxiliar 11). Consideramos un valor de p = 0.5"
      ],
      "metadata": {
        "id": "a4R6417v3trU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backtracking(bo,d):\n",
        "  a_barra = 1\n",
        "  p = 0.5\n",
        "  c = 0.9\n",
        "  a = a_barra\n",
        "  while True:\n",
        "    if r(bo + a*d)[0] <= r(bo)[0] + c*a*np.dot(np.transpose(gradf(bo)),d):\n",
        "      break\n",
        "    else:\n",
        "      a = p*a\n",
        "\n",
        "  return a"
      ],
      "metadata": {
        "id": "6pK266pi_95o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Función método gradiente"
      ],
      "metadata": {
        "id": "TMiqL-eyB1vS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función recibe un punto b0 y un str con el tipo de paso que se debe usar. Retorna una lista con el punto óptimo b, su valor optimo robj y el numero de iteraciones que realiza el algoritmo. \n",
        "\n",
        "Como función auxiliar, definimos la norma euclideana. El algoritmo consitira en iniciar con b = b0, para luego ir actualizando el valor de b siguiendo la regla b = b + ad, en donde d es -gradf(b) y a el paso, que puede ser de busqueda exacta, backtracking o de line_search de scipy.optimize. El algoritmo se detiene cuando la norma de gradf(b) es menor a 0.00001 o cuando ocurren mas de 100000 iteraciones."
      ],
      "metadata": {
        "id": "9VsCQ10R4Cky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norma(z):\n",
        "  l = len(z)\n",
        "  suma = 0\n",
        "  for i in range(l):\n",
        "    suma += (z[i] ** 2)\n",
        "  return np.sqrt(suma)\n",
        "\n",
        "#recibe un punto inicial bo\n",
        "#y un str con el tipo de paso que se debe usar\n",
        "#retorna una lista con el punto optimo b, su valor\n",
        "#optimo robj y el numero de iteraciones\n",
        "def MetodoGradiente(b0,pasos):\n",
        "\n",
        "  #busqueda exacta:\n",
        "  if pasos == 'be':\n",
        "    iter = 0 #numero de iteraciones\n",
        "    b = b0 #punto optimo \n",
        "    while iter < 100000: #max de iteraciones\n",
        "      #verificamos si la norma del gradiente es menor que epsilon\n",
        "      if norma(gradf(b)) < 0.00001:\n",
        "        iter += 1\n",
        "        break\n",
        "        \n",
        "      d = -gradf(b) #dirreccion de descenso\n",
        "      a = busquedaexacta(b,d) #paso\n",
        "      b = b + a*d #actualizamos el valor de b\n",
        "      iter += 1\n",
        "\n",
        "    robj = r(b)\n",
        "    return [b,robj,iter]\n",
        "  \n",
        "\n",
        "  #backtracking:\n",
        "  elif pasos == 'bt':\n",
        "    iter = 0 #numero de iteraciones\n",
        "    b = b0 #punto optimo \n",
        "    while iter < 100000: #max de iteraciones\n",
        "      #verificamos si la norma del gradiente es menor que epsilon\n",
        "      if norma(gradf(b)) < 0.00001:\n",
        "        iter += 1\n",
        "        break\n",
        "        \n",
        "      d = -gradf(b) #direccion de descenso\n",
        "      a = backtracking(b,d) #paso\n",
        "      b = b + a*d #actualizamos el valor de b\n",
        "      iter += 1\n",
        "\n",
        "    robj = r(b)\n",
        "    return [b,robj,iter]\n",
        "\n",
        "\n",
        "  #optimize:\n",
        "  elif pasos == 'o':\n",
        "    iter = 0 #numero de iteraciones\n",
        "    b = b0 #punto optimo \n",
        "    while iter < 100000: #max de iteraciones\n",
        "      #verificamos si la norma del gradiente es menor que epsilon\n",
        "      if norma(gradf(b)) < 0.00001:\n",
        "        iter += 1\n",
        "        break\n",
        "        \n",
        "      d = -gradf(b) #direccion de descenso\n",
        "      a =  scipy.optimize.line_search(r,gradf,b,d)[0] #paso\n",
        "      #caso donde no existe alpha:\n",
        "      if a == None:\n",
        "        return 'metodo no converge'\n",
        "      b = b + a*d #actualizamos el valor de b\n",
        "      iter += 1\n",
        "\n",
        "    robj = r(b)\n",
        "    return [b,robj,iter]\n",
        "\n",
        "\n",
        "  else:\n",
        "    return 'paso no existente'"
      ],
      "metadata": {
        "id": "ZNxVnbLJB-Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Función método de Newton"
      ],
      "metadata": {
        "id": "FL5VLhHBtdkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De forma casi análoga, esta función recibe un punto b0 y un str con el tipo de paso que se debe usar. Retorna una lista con el punto óptimo b, su valor optimo robj y el numero de iteraciones que realiza el algoritmo.\n",
        "\n",
        " El algoritmo consitira en iniciar con b = b0, para luego ir actualizando el valor de b siguiendo la regla b = b + ad, en donde d es el producto entre -gradf(b) y la inversa de hessf(b) y a el paso, que puede ser de busqueda exacta, backtracking o de line_search de scipy.optimize. El algoritmo se detiene cuando la norma de gradf es menor a 0.00001 o cuando ocurren mas de 100000 iteraciones."
      ],
      "metadata": {
        "id": "aEaDiYUH6T73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MetodoNewton(b0,pasos):\n",
        "\n",
        "  #busqueda exacta:\n",
        "  if pasos == 'be':\n",
        "    iter = 0 #numero de iteraciones\n",
        "    b = b0 #punto optimo \n",
        "    while iter < 100000: #max de iteraciones\n",
        "      #verificamos si la norma del gradiente es menor que epsilon\n",
        "      if norma(gradf(b)) < 0.00001:\n",
        "        iter += 1\n",
        "        break\n",
        "\n",
        "      hinv = np.linalg.inv(hessf(b))  #inversa del heassiano\n",
        "      d = -np.dot(hinv,gradf(b)) #dirreccion de descenso\n",
        "      a = busquedaexacta(b,d) #paso\n",
        "      b = b + a*d #actualizamos el valor de b\n",
        "      iter += 1\n",
        "\n",
        "    robj = r(b)\n",
        "    return [b,robj,iter]\n",
        "  \n",
        "\n",
        "  #backtracking:\n",
        "  elif pasos == 'bt':\n",
        "    iter = 0 #numero de iteraciones\n",
        "    b = b0 #punto optimo \n",
        "    while iter < 100000: #max de iteraciones\n",
        "      #verificamos si la norma del gradiente es menor que epsilon\n",
        "      if norma(gradf(b)) < 0.00001:\n",
        "        iter += 1\n",
        "        break\n",
        "        \n",
        "      hinv = np.linalg.inv(hessf(b))  #inversa del heassiano\n",
        "      d = -np.dot(hinv,gradf(b)) #dirreccion de descenso\n",
        "      a = backtracking(b,d) #paso\n",
        "      b = b + a*d #actualizamos el valor de b\n",
        "      iter += 1\n",
        "\n",
        "    robj = r(b)\n",
        "    return [b,robj,iter]\n",
        "\n",
        "\n",
        "  #optimize:\n",
        "  elif pasos == 'o':\n",
        "    iter = 0 #numero de iteraciones\n",
        "    b = b0 #punto optimo \n",
        "    while iter < 100000: #max de iteraciones\n",
        "      #verificamos si la norma del gradiente es menor que epsilon\n",
        "      if norma(gradf(b)) < 0.00001:\n",
        "        iter += 1\n",
        "        break\n",
        "        \n",
        "      hinv = np.linalg.inv(hessf(b))  #inversa del heassiano\n",
        "      d = -np.dot(hinv,gradf(b)) #dirreccion de descenso\n",
        "      a =  scipy.optimize.line_search(r,gradf,b,d)[0] #paso\n",
        "      #caso donde no existe alpha:\n",
        "      if a == None:\n",
        "        return 'metodo no converge'\n",
        "      b = b + a*d #actualizamos el valor de b\n",
        "      iter += 1\n",
        "\n",
        "    robj = r(b)\n",
        "    return [b,robj,iter]\n",
        "\n",
        "\n",
        "  else:\n",
        "    return 'paso no existente'"
      ],
      "metadata": {
        "id": "LKsU8Yl9th_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## P3"
      ],
      "metadata": {
        "id": "rDSpBCkNK0Zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para rellenar la tabla, primero debemos testear los métodos, calculando sus valores y midiendo el tiempo que se demoran utilizando la libreria time."
      ],
      "metadata": {
        "id": "EucOXHDpK2F5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b1 = np.array([1,1,1]) #punto inicial"
      ],
      "metadata": {
        "id": "wQJJNkwqGENX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gradiente busqueda exacta:\n",
        "\n",
        "t1 = time.time()\n",
        "print('gradiente busqueda exacta: ')\n",
        "print('')\n",
        "resp = MetodoGradiente(b1,'be')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3qqKFM1OZHZ",
        "outputId": "db97f011-5a4a-4c31-c1e6-be16d9fd436b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradiente busqueda exacta: \n",
            "\n",
            "b óptimo:  [ 0.30822855 -0.04522163  0.18509475]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  26\n",
            "tiempo:  0.14033770561218262 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gradiente backtracking:\n",
        "t1 = time.time()\n",
        "print('gradiente backtracking: ')\n",
        "print('')\n",
        "resp = MetodoGradiente(b1,'bt')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyePWBZtOWG9",
        "outputId": "214beb8f-6691-4d26-93a3-dc76a04362e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradiente backtracking: \n",
            "\n",
            "b óptimo:  [ 0.30822464 -0.04519791  0.18507516]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  123\n",
            "tiempo:  0.15927696228027344 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gradiente line search optimize:\n",
        "\n",
        "t1 = time.time()\n",
        "print('gradiente line search optimize: ')\n",
        "print('')\n",
        "resp = MetodoGradiente(b1,'o')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh430bn9Ob8D",
        "outputId": "b355f892-d04d-4423-eeda-d826f40f3b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradiente line search optimize: \n",
            "\n",
            "b óptimo:  [ 0.30818755 -0.04519713  0.18509919]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  104\n",
            "tiempo:  0.12311673164367676 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#newton busqueda exacta:\n",
        "\n",
        "t1 = time.time()\n",
        "print('Newton busqueda exacta: ')\n",
        "print('')\n",
        "resp = MetodoNewton(b1,'be')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVefVQNeOiLx",
        "outputId": "2f0bc403-3863-4977-bc30-d6f83b619a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newton busqueda exacta: \n",
            "\n",
            "b óptimo:  [ 0.30811787 -0.04519188  0.18513565]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  5\n",
            "tiempo:  0.05759716033935547 segundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#newton backtracking:\n",
        "\n",
        "t1 = time.time()\n",
        "print('Newton backtracking: ')\n",
        "print('')\n",
        "resp = MetodoNewton(b1,'bt')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjMKoXUUOhYq",
        "outputId": "2ad72a50-f604-466b-e68d-c07d1e7231e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newton backtracking: \n",
            "\n",
            "b óptimo:  [ 0.30812142 -0.04518976  0.18513744]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  87\n",
            "tiempo:  0.4374406337738037 segundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#newton line search optimize:\n",
        "\n",
        "t1 = time.time()\n",
        "print('Newton line search optimize: ')\n",
        "print('')\n",
        "resp = MetodoNewton(b1,'o')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDo4enSYOksf",
        "outputId": "2103ad82-8c49-4196-e1f9-5ce8607bfa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newton line search optimize: \n",
            "\n",
            "b óptimo:  [ 0.3080962  -0.04519037  0.18514301]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  6\n",
            "tiempo:  0.03347182273864746 segundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto rellenamos los datos en una tabla:"
      ],
      "metadata": {
        "id": "j79WBLkwXs1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\begin{array}{|c|c|} \\hline\n",
        "\\text{Método} & Paso & \\text{Punto inicial} & \\text{Óptimo} & \\text{Valor objetivo} & Iteraciones & Tiempo [s] \\\\ \\hline\n",
        "Gradiente       & \\text{Búsqueda exacta}         & (1,1,1)                                                          & (0.30822, -0.04522,  0.18509)                                        & 0.62960812                                                         & 26                                                                    & 0.13064                 \\\\ \\hline\n",
        "Gradiente       & Backtracking            & (1,1,1)                                                          & (0.30822, -0.04519,  0.18507)                                         & 0.62960812                                                        & 123                                                                   & 0.15126                 \\\\ \\hline\n",
        "Gradiente       & \\text{Line search de optimize} & (1,1,1)                                                          & (0.30818, -0.04519,  0.18509)                                        & 0.62960812                                                          & 104                                                                  & 0.09818                 \\\\ \\hline\n",
        "Newton          & \\text{Búsqueda exacta}         & (1,1,1)                                                          & (0.30811, -0.04519,  0.18513)                                        & 0.62960812                                                          & 5                                                                     & 0.04390                 \\\\ \\hline\n",
        "Newton          & Backtracking            & (1,1,1)                                                          & (0.30812, -0.04518,  0.18513)                                         & 0.62960812                                                         & 87                                                                    & 0.37921                 \\\\ \\hline\n",
        "Newton          & \\text{Line search de optimize} & (1,1,1)                                                          & (0.30809, -0.04519,  0.18514)                                         & 0.62960812                                                         & 6                                                                     & 0.02201                 \\\\ \\hline\n",
        "\\end{array}$"
      ],
      "metadata": {
        "id": "BOvjH-ghY0ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como observación, los tiempos pueden variar para distintas ejecuciones del código."
      ],
      "metadata": {
        "id": "U9GxyzgPSTaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## P4"
      ],
      "metadata": {
        "id": "FeDXsnixbWdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notamos que todos los métodos llegaron al mismo valor óptimo, salvo pequeñas diferencias decimales. Luego, para decidir cual es el mejor método debemos considerar la eficiencia de estos. Notamos que el método de Newton con paso de line search de optimize obtiene el menor tiempo y está a una repetición del menor numero de repeticiones, por lo que lo consideramos como el mejor método para este ejemplo."
      ],
      "metadata": {
        "id": "qXyejhVdbZRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora probemos este método con otros puntos iniciales de igual manera que lo hicimos en la parte anterior:"
      ],
      "metadata": {
        "id": "m5KRaF13dRza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b2 = (-1,-1,-1)\n",
        "b3 = (10,10,10)\n",
        "b4 = (-1,0,1)"
      ],
      "metadata": {
        "id": "uUx9Qq-gdaij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b2\n",
        "\n",
        "t1 = time.time()\n",
        "print('punto inicial b2: ')\n",
        "print('')\n",
        "resp = MetodoNewton(b2,'o')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DhT5yfAetAs",
        "outputId": "40207294-9f6f-4855-f180-9cd772104db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punto inicial b2: \n",
            "\n",
            "b óptimo:  [ 0.30811874 -0.04519347  0.18513605]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  7\n",
            "tiempo:  0.02793264389038086 segundos\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la dirrección b3 notamos que su hessiano es una matriz singular (determinante = 0), luego su inversa no se puede calcular y el método de Newton no nos sirve:"
      ],
      "metadata": {
        "id": "T4LpabW7Bcpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(hessf(b3))\n",
        "det = np.linalg.det(hessf(b3))\n",
        "print('Determinante: ', det)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfT53MdU_kRU",
        "outputId": "200ce23f-be7a-49d1-bd31-4b725da70e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.79006489e-15 7.79006489e-15 7.79006489e-15]\n",
            " [7.79006489e-15 7.79006489e-15 7.79006489e-15]\n",
            " [7.79006489e-15 7.79006489e-15 7.79006489e-15]]\n",
            "Determinante:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b4\n",
        "\n",
        "t1 = time.time()\n",
        "print('punto inicial b4: ')\n",
        "print('')\n",
        "resp = MetodoNewton(b4,'o')\n",
        "print('b óptimo: ', resp[0])\n",
        "print('valor óptimo: ', resp[1])\n",
        "print('número de iteraciones: ', resp[2])\n",
        "t2 = time.time()\n",
        "print('tiempo: ', t2-t1, 'segundos')\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiiKkT9CfBS2",
        "outputId": "e070faf0-857e-4bdb-bddd-8c74aec3ab1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punto inicial b4: \n",
            "\n",
            "b óptimo:  [ 0.30811933 -0.04519369  0.185136  ]\n",
            "valor óptimo:  [0.62960812]\n",
            "número de iteraciones:  5\n",
            "tiempo:  0.01907515525817871 segundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## P5"
      ],
      "metadata": {
        "id": "_kYKBgUPbK9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al ver los resultados de la parte anterior, notamos que todos obtienen el mismo valor óptimo, salvo pequeñas diferencias decimales, luego compararemos basandonos en su eficiencia. Anotamos los resultados anotándolos en una tabla:"
      ],
      "metadata": {
        "id": "kUtrBnImEg_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\begin{array}{|c|c|} \\hline\n",
        "\\text{Punto inicial} & Iteraciones & \\text{Tiempo [s]} \\\\ \\hline\n",
        "b1 & 6 & 0.02201 \\\\ \\hline\n",
        "b2 & 7 & 0.02977 \\\\\\hline\n",
        "b3 & - & -  \\\\ \\hline\n",
        "b4 & 5 & 0.01963 \\\\ \\hline\n",
        "\\end{array}$"
      ],
      "metadata": {
        "id": "pVurDNFjFAG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al tener el menor tiempo y el menor numero de iteraciones, consideramos al punto b4 = (-1,0,1) como el mejor punto inicial. Concluimos entonces que el valor óptimo de b es b = (0.30811933, -0.04519369, 0.185136)"
      ],
      "metadata": {
        "id": "qeqzEHjfaktQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora analicemos los correos de test:"
      ],
      "metadata": {
        "id": "L8rFWnUvcP47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correo test 1:** \n",
        "\n",
        "Es un correo en español, de un servidor institucional, tiene menos de 50 palabras y no es considerado como spam. Con esto:\n",
        "\n",
        "$xt_1^1 = 1, xt_1^2 = 2, xt_1^3 = 1, yt_1 = 0$"
      ],
      "metadata": {
        "id": "vy2DfkbGcWgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correo test 2:** \n",
        "\n",
        "Es un correo en ingles, de un servidor conocido (gmail), tiene mas de 100 palabras y es considerado como spam. Con esto:\n",
        "\n",
        "$xt_2^1 = 2, xt_2^2 = 1, xt_2^3 = 3, yt_2 = 1$"
      ],
      "metadata": {
        "id": "X_Md3ruNeEpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correo test 3:** \n",
        "\n",
        "Es un correo en español, de un servidor desconocido, tiene mas de 100 palabras y es considerado como spam. Con esto:\n",
        "\n",
        "$xt_3^1 = 1, xt_3^2 = 3, xt_3^3 = 3, yt_3 = 1$"
      ],
      "metadata": {
        "id": "0E7pld6uew2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escribimos los xt en forma vectorial:"
      ],
      "metadata": {
        "id": "tHIHoxG2fPsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xt1 = np.array([1,2,1])\n",
        "xt2 = np.array([2,1,3])\n",
        "xt3 = np.array([1,3,3])"
      ],
      "metadata": {
        "id": "TZmiksm0cVzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, para realizar las predicciones, calculamo el valor al realizar la regresión, osea calcular h(x_test * b_optimo):"
      ],
      "metadata": {
        "id": "hQNvaUalfxll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bopt = np.array([0.30811933, -0.04519369, 0.185136]) #optimo encontrado\n",
        "ypred1 = h(np.dot(xt1,bopt))\n",
        "ypred2 = h(np.dot(xt2,bopt))\n",
        "ypred3 = h(np.dot(xt3,bopt))\n",
        "print('Predicción correo 1: ', ypred1)\n",
        "print('Predicción correo 2: ', ypred2)\n",
        "print('Predicción correo 3: ', ypred3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgHiY3y-gC5r",
        "outputId": "1c0f059e-3ccd-4cad-ef7d-477875e6497f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicción correo 1:  0.5993765204770101\n",
            "Predicción correo 2:  0.7551837133996202\n",
            "Predicción correo 3:  0.6743544317804203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anotamos los resultados en una tabla:"
      ],
      "metadata": {
        "id": "dl1-e7rArDeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\begin{array}{|c|c|} \\hline\n",
        " & \\text{prediccion} & \\text{valor esperado} \\\\ \\hline\n",
        "\\text{correo 1} & 0.5993 & 0 \\\\ \\hline\n",
        "\\text{correo 2} & 0.7551 & 1 \\\\\\hline\n",
        "\\text{correo 3} & 0.6743 & 1  \\\\ \\hline\n",
        "\\end{array}$"
      ],
      "metadata": {
        "id": "L_pROM1vrQjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notamos que los valores de la predicción se alejan un poco  de lo esperado. El correo 1 deberia ser mas cercano a 0, sin embargo se acerca a 0.6, esto se puede deber a que en mi perspectiva, esto si es un correo de spam, por lo que mi matriz de categorias no se acerca a lo planteado en el enunciado. Los correos 2 y 3 estan mas cerca de 1 que 0, sin embargo, son un poco lejanos.\n",
        "\n",
        "Probablemente, los resultados podrian mejorar si se considera una matriz de categorias más grande (entrenar con más ejemplos) o si se consideran más variables sobre el correo."
      ],
      "metadata": {
        "id": "T41Am-9lsLN5"
      }
    }
  ]
}